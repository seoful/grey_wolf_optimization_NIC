{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identity = pd.read_csv('train_identity.csv')\n",
    "train_transaction = pd.read_csv('train_transaction.csv')\n",
    "# train_identity =train_identity.head(n=500)\n",
    "# train_transaction = train_transaction.head(n=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "df = train_transaction.join(train_identity,how='left',on='TransactionID',lsuffix='_left', rsuffix='_right')\n",
    "df.drop(inplace=True,columns=['TransactionID_left','TransactionID_right'])\n",
    "del train_identity\n",
    "del train_transaction\n",
    "\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "\n",
    "X_train_na_cols = X.isna().all()\n",
    "        \n",
    "X = X.drop(X.columns[X_train_na_cols], axis=1)\n",
    "        \n",
    "X_train_na_cols = X.isna().any()\n",
    "print(len(X.columns[X_train_na_cols]))\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit(X)\n",
    "X = pd.DataFrame(imputer.transform(X), columns=X.columns)\n",
    "X_train_na_cols = X.isna().any()\n",
    "print(len(X.columns[X_train_na_cols]))\n",
    "X = X.apply(pd.to_numeric, errors='ignore', axis=1)\n",
    "X = X.drop('TransactionDT', axis=1)\n",
    "X = pd.get_dummies(X, dtype=float)\n",
    "print(X.shape)\n",
    "corr = X.corr()\n",
    "m = (corr.mask(np.eye(len(corr), dtype=bool)).abs() > 0.75).any()\n",
    "        \n",
    "print(sum(m))\n",
    "raw = corr.loc[m, m]\n",
    "for i in raw:\n",
    "    X = X.drop(i, axis=1)\n",
    "print(X.shape)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = pd.DataFrame(scaler.transform(X), columns=X.columns)\n",
    "X.to_csv('edited_train.csv', index=False)\n",
    "X.iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    \n",
    "    def __init__(self,X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def encode(self, features_vector) -> pd.DataFrame:\n",
    "        return pd.get_dummies(self.X.iloc[:,np.array(features_vector).astype(bool)],dtype=float)\n",
    "        \n",
    "        \n",
    "proc = Encoder(X,y)\n",
    "# train_transaction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class Estimator:\n",
    "    def __init__(self,cv, model_generator):\n",
    "        self.cv = cv\n",
    "        self.model_generator = model_generator\n",
    "\n",
    "    def get_score(self,X, y) -> float:\n",
    "        return cross_val_score(self.model_generator(), X,y, cv=self.cv,scoring='balanced_accuracy')\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self.model_generator().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreyWolfOptimizer:\n",
    "    \n",
    "    def __init__(self,estimator: Estimator, preprocessor: Encoder):\n",
    "        self.estimator = estimator\n",
    "        self.encoder = preprocessor\n",
    "        self.train_score_history_ = []\n",
    "        self.fitted_model_ = None\n",
    "        self.features_n_ = None\n",
    "\n",
    "    def _init_population(self, features_n, population_size):\n",
    "        population = []\n",
    "        individual = []\n",
    "        for _ in range(population_size):\n",
    "            individual = np.random.random(size=len(features_n))\n",
    "            population.append(individual)\n",
    "        return population\n",
    "\n",
    "    def run(self, iterations = 50, threshold = 0.5, population_size = 10):\n",
    "        \n",
    "        #Init algo\n",
    "        n = self.encoder.n # number of features\n",
    "        population = self._init_population(population_size=population_size,features_n=n)\n",
    "\n",
    "        bar = tqdm(range(iterations))\n",
    "\n",
    "        for i in bar: #Epochs\n",
    "            step = i * ((2-0) / iterations)\n",
    "            population = sorted(population, key=lambda x: self._calculate_cost(x,threshold),reverse = True)\n",
    "            self.train_score_history_.append(population[0])\n",
    "            X = population[:3] # alpha, beta, delta\n",
    "            a = np.full((1, n), 2 - step).ravel()\n",
    "            new_population = []\n",
    "            for individual in population:\n",
    "                r1 = np.random.random(size=n)\n",
    "                r2 = np.random.random(size=n)\n",
    "                A = 2 * a * r1 - a\n",
    "                C = 2 * r2\n",
    "                new_individual = np.full((1, n), 0.0).ravel()\n",
    "                for x in X:\n",
    "                    D = abs(C * x - individual)\n",
    "                    new_x = x - A * D\n",
    "                    new_individual = new_individual + new_x\n",
    "                new_population.append(new_individual / 3)\n",
    "            \n",
    "            population = new_population\n",
    "\n",
    "        # Best solution after n iterations\n",
    "        population = sorted(population, key=lambda x: self._calculate_cost(x,threshold),reverse = True)\n",
    "        X_alpha = population[0]\n",
    "        self.train_score_history_.append(X_alpha)\n",
    "        self.fitted_model_ = self.estimator.fit(self.encoder.encode(np.array(X_alpha) >= threshold),self.encoder.y)\n",
    "        self.features_n_ = np.count_nonzero(X_alpha >= threshold)\n",
    "\n",
    "\n",
    "    def _calculate_cost(self, weights, threshold):\n",
    "        X = self.encoder.encode(np.array(weights) >= threshold)\n",
    "        y = self.encoder.y\n",
    "\n",
    "        return self.estimator.get_score(X,y)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
